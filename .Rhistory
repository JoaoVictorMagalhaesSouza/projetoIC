geraNuvem <- function(acao){
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 100,since = "2019-25-01")
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("#VALE3")
########################################################
#Nuvem de palavras:
#######################################################
geraNuvem <- function(acao){
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 100,since = "2019-01-25")
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("#VALE3")
########################################################
#Nuvem de palavras:
#######################################################
geraNuvem <- function(acao){
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 100,since = "2019-01-25",until = "2019-01-25")
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("#VALE3")
########################################################
#Nuvem de palavras:
#######################################################
geraNuvem <- function(acao){
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 100,since = "2019-01-24",until = "2019-01-25")
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("#VALE3")
########################################################
#Nuvem de palavras:
#######################################################
geraNuvem <- function(acao){
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 100,since = "2020-01-01",until = "2020-01-25")
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("#WEGE")
geraNuvem("#WEG")
########################################################
#Nuvem de palavras:
#######################################################
Sys.Date()
########################################################
#Nuvem de palavras:
#######################################################
Sys.Date()-7
geraNuvem <- function(acao){
dataIni = Sys.Date()-7
dataFinal = Sys.Date()
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 100,since = dataIni,until = dataFinal)
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("#WEG")
geraNuvem <- function(acao){
dataIni = as.character(Sys.Date()-7)
dataFinal = as.character(Sys.Date())
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 100,since = dataIni,until = dataFinal)
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("#WEG")
geraNuvem("#WEG3")
geraNuvem("#WEG SA")
geraNuvem("#WEGE3")
geraNuvem("Bolsonaro")
geraNuvem("Lula")
geraNuvem <- function(acao){
dataIni = as.character(Sys.Date()-7)
dataFinal = as.character(Sys.Date())
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 2000,since = dataIni,until = dataFinal)
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("Lula")
geraNuvem <- function(acao){
dataIni = as.character(Sys.Date()-7)
dataFinal = as.character(Sys.Date())
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 2000,since = dataIni,until = dataFinal)
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("VALE3")
geraNuvem <- function(acao){
dataIni = as.character(Sys.Date()-7)
dataFinal = as.character(Sys.Date())
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 2000,since = dataIni,until = dataFinal)
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
#view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("WEGE")
geraNuvem <- function(acao){
dataIni = as.character(Sys.Date()-7)
dataFinal = as.character(Sys.Date())
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 2000,since = dataIni,until = dataFinal)
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("WEGE")
geraNuvem <- function(acao){
dataIni = as.character(Sys.Date()-7)
dataFinal = as.character(Sys.Date())
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 10000,since = dataIni,until = dataFinal)
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("WEGE")
geraNuvem("Bolsonaro")
geraNuvem("CIELO")
geraNuvem <- function(acao){
dataIni = as.character(Sys.Date()-7)
dataFinal = as.character(Sys.Date())
setup_twitter_oauth("GO2vKO8fZPICcYFry4WcbS397", "HReBTbs6fLVm4PhCpTjWdMJn82kAg8gX6BHHtv307vP5D0SCKt", "1402605860891791364-LKt10SqzmAEG652nP9YtveYu6JxVE0", "yTbybjYtbBqRZtbqNhGhFjzX861oHqLTzmxkaqtgCPb8R")
tweets <- searchTwitter(acao,lang="pt", n = 2000,since = dataIni,until = dataFinal)
#Transformar lista em DF
tweets <- tweets %>% twListToDF()
view(tweets)
tweetsText <- tweets$text
docs <- Corpus(VectorSource(tweetsText))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("portuguese"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
set.seed(1234)
wordcloud(words = df$word, freq = df$freq, min.freq = 1,max.words=75, random.order=FALSE, rot.per=0.35,  colors=brewer.pal(8, "Dark2"))
#wordcloud2(data=df, size=1.6, color='random-dark')
}
geraNuvem("CIELO")
geraNuvem("CIEL3")
geraNuvem("#CIEL3")
geraNuvem("#MGLU3")
geraNuvem("#COPEL")
geraNuvem("#BRFS3")
geraNuvem("#ECOR3")
geraNuvem("Bitcoin")
shiny::runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
####################################################################
##Funcoes auxiliares:
#############################################################
names(BancoDeDados_Acoes)
nomesCod <- nomesCod[-1]
####################################################################
##Funcoes auxiliares:
#############################################################
nomesCod <- names(BancoDeDados_Acoes)
nomesCod <- nomesCod[-1]
nomesCod
####################################################################
##Funcoes auxiliares:
#############################################################
names(BancoDeDados_Acoes[-1])
# Define UI for application
shinyUI(fluidPage(
navbarPage(title="ANÁLISE DA BOVESPA",
tabPanel("ATIVO",
tabsetPanel(
tabPanel("Série Temporal",
fluidRow(column(3,
selectInput("Ativo1",))
column(9,
DT::dataTableOutput("table1")))),
##
tabPanel("Boxplot",
fluidRow(column(3,
selectInput("Opções",
strong("Escolha uma opção:"),
choices=c("Opção 1"="age2",
"Opção 2"="age3"),
selected = "age2")),
column(9,
plotlyOutput("plot1", height = 800))))
##
)# barra de navegacao interna
),# barra de navegacao superior (Dados do Participante)
tabPanel("Menu2",
tabsetPanel(
##
tabPanel("SubMenu2.1",
fluidRow(column(9,
leafletOutput("plot2", height = 600)))),
tabPanel("SubMenu2.2",
fluidRow(column(9,
plotlyOutput("plot3", height = 600))))
)# barra de navegacao interna
)# barra de navegacao superior (Dados da Escola)
)#navbarPage
)#fluidPage
)#shinyUI
runApp('Shiny')
runApp('Shiny')
runApp()
runApp()
runApp()
runApp('Shiny')
runApp('Shiny')
shiny::runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
# library("ggthemes")
# library("treemap")
library("leaflet")
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
Sys.time()
Sys.time()
Sys.timezone()
saveRDS(df_emp,"teste")
saveRDS(df_emp,"teste.rds")
View(dados)
rm(dados)
View(f1)
rm(f1)
saveRDS(BancoDeDados_Acoes,"BancoDeDados_Acoes.rds")
##############################################################################
## DATA SOURCES
BancoDeDados_Acoes <- readRDS("BancoDeDados_Acoes.rds")
##############################################################################
## DATA SOURCES
xis <- readRDS("BancoDeDados_Acoes.rds")
##############################################################################
## DATA SOURCES
rm(xis)
##############################################################################
Sys.time()[2]
##############################################################################
Sys.time()[1]
##############################################################################
strsplit(Sys.time()," ")
##############################################################################
strsplit(as.character(Sys.time())," ")
##############################################################################
hora = strsplit(as.character(Sys.time())," ")[2]
View(hora)
view(hora)
View(hora)
##############################################################################
hora = as.character(strsplit(as.character(Sys.time())," "))
view(hora)
##############################################################################
hora = strsplit(as.character(Sys.time())," ")
view(hora)
view(hora[2])
view(hora[1])
view(hora[1][2])
view(hora[2][1])
view(hora[[1]][2])
hora <- hora[[1]][2]
view(hora[[1]][2])
view(hora)
view(hora[1])
hora[1]
view(as.character(hora[2]))
as.character(hora[2])
typeof(hora)
hora <- strsplit(hora,":")
hora <- hora[[1]][1]
minuto <- hora[[1]][2]
hora <- strsplit(hora,":")
View(hora)
hora <- strsplit(hora,":")
##############################################################################
hora <- strsplit(as.character(Sys.time())," ")
hora <- hora[[1]][2]
hora <- strsplit(hora,":")
View(hora)
##############################################################################
horas <- strsplit(as.character(Sys.time())," ")
horas <- horas[[1]][2]
horas <- strsplit(horas,":")
hora <- horas[[1]][1]
minuto <- hora[[1]][2]
minuto <- horas[[1]][2]
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
shiny::runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
runApp('Shiny')
tema <- theme(plot.title = element_text(family = "Helvetica", face = "bold", size = (15)),
legend.title = element_text(colour = "steelblue",  face = "bold.italic", family = "Helvetica"),
legend.text = element_text(face = "italic", colour="steelblue4",family = "Helvetica"),
axis.title = element_text(family = "Helvetica", size = (10), colour = "steelblue4"),
axis.text = element_text(family = "Courier", colour = "cornflowerblue", size = (10)))
runApp('Shiny')
View(tema)
runApp('Shiny')
